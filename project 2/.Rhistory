p<-predict(reduced.model,newdata=college.test)
error1 <- mean(((college.test$Outstate)-p)^2)
error1
#Make a x matrix and y vector for both the training and testing set
x_train<-model.matrix(Outstate~.,college.train)[,-1]
y_train<-college.train$Outstate
x_test<-model.matrix(Outstate~.,college.test)[,-1]
y_test<-college.test$Outstate
set.seed(5555)
#perform the Lasso method and choose the best model using CV
lasso.mod = glmnet(x_train,y_train,alpha=1) #lasso method on train set
cv.lasso = cv.glmnet(x_train,y_train,alpha=1) #CV on train set
lambda.best = cv.lasso$lambda.min #select best lambda
lambda.best
#find the test MSE
predictions<-predict(lasso.mod,s=lambda.best,newx=x_test)
error2 <- mean((predictions-y_test)^2) #test MSE
error2
c<-coef(lasso.mod,s=lambda.best,exact=TRUE)
inds<-which(c!=0)
variables<-row.names(c)[inds]
variables
ds1 = college.train[c("Private", "Outstate")] #binary variable
ds2 = college.train[c("Room.Board", "Outstate")]
ds3 = college.train[c("Terminal", "Outstate")]
ds4 = college.train[c("perc.alumni", "Outstate")]
ds5 = college.train[c("Expend", "Outstate")]
ds6 = college.train[c("Grad.Rate", "Outstate")]
par(mfrow=c(2,3))
plot(ds1)
plot(ds2)
plot(ds3)
plot(ds4)
plot(ds5)
plot(ds6)
library(ggplot2)
#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
# plot of training data
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) + geom_point(color = "darkgrey") +
labs(title = "Polynomial regression")
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[tr, ])
# dataframe of predicted values - use fitted values (for mpg) and horsepower
# from training set and add column (factor) for degree
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit, degree = as.factor(rep(d,
length(mod$fit)))))
# calculate mean MSE - this is returned in the MSE variable
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-traind.ind, 2])^2)
}
library(ggplot2)
#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
# plot of training data
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) + geom_point(color = "darkgrey") +
labs(title = "Polynomial regression")
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[train.ind, ])
# dataframe of predicted values - use fitted values (for mpg) and horsepower
# from training set and add column (factor) for degree
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit, degree = as.factor(rep(d,
length(mod$fit)))))
# calculate mean MSE - this is returned in the MSE variable
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-traind.ind, 2])^2)
}
library(ggplot2)
#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
# plot of training data
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) + geom_point(color = "darkgrey") +
labs(title = "Polynomial regression")
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[train.ind, ])
# dataframe of predicted values - use fitted values (for mpg) and horsepower
# from training set and add column (factor) for degree
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit, degree = as.factor(rep(d,
length(mod$fit)))))
# calculate mean MSE - this is returned in the MSE variable
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-train.ind, 2])^2)
}
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values
library(ggplot2)
#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
# plot of training data
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) + geom_point(color = "darkgrey") +
labs(title = "Polynomial regression")
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values
MSE = list(rep(0, 10))  #make a empty variable to store predicted values
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[train.ind, ])
# dataframe of predicted values - use fitted values (for mpg) and horsepower
# from training set and add column (factor) for degree
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit, degree = as.factor(rep(d,
length(mod$fit)))))
# calculate mean MSE - this is returned in the MSE variable
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-train.ind, 2])^2)
}
# plot fitted values for different degrees
ggplot(data = ds[traind.ind, ], aes(x = Terminal, y = Outstate)) + geom_point(color = "darkgrey") +
labs(title = "Polynomial regression") + geom_line(data = dat, aes(x = Terminal,
y = Outstate, color = degree))
library(ggplot2)
#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
# plot of training data
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) + geom_point(color = "darkgrey") +
labs(title = "Polynomial regression")
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values
MSE = list(rep(0, 10))  #make a empty variable to store predicted values
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[train.ind, ])
# dataframe of predicted values - use fitted values (for mpg) and horsepower
# from training set and add column (factor) for degree
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit, degree = as.factor(rep(d,
length(mod$fit)))))
# calculate mean MSE - this is returned in the MSE variable
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-train.ind, 2])^2)
}
# plot fitted values for different degrees
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) + geom_point(color = "darkgrey") +
labs(title = "Polynomial regression") + geom_line(data = dat, aes(x = Terminal,
y = Outstate, color = degree))
library(ggplot2)
#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values
MSE = list(rep(0, 10))  #make a empty variable to store predicted values
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[train.ind, ])
# dataframe of predicted values - use fitted values (for mpg) and horsepower
# from training set and add column (factor) for degree
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit, degree = as.factor(rep(d,
length(mod$fit)))))
# calculate mean MSE - this is returned in the MSE variable
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-train.ind, 2])^2)
}
# plot fitted values for different degrees
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) + geom_point(color = "darkgrey") +
labs(title = "Polynomial regression") + geom_line(data = dat, aes(x = Terminal,
y = Outstate, color = degree))
?rbind
rbind
dat
library(splines)
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(splines)
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Outstate", ylab="Expend",)
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(splines)
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate",)
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(splines)
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(ggplot2)
#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values for each degree
MSE = list(rep(0, 10))  #make a empty variable to store MSE for each degree
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[train.ind, ])
#dataframe for Terminal and Outstate showing result for each degree over all samples
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit,
degree = as.factor(rep(d,length(mod$fit)))))
# training MSE
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-train.ind, 2])^2)
}
# plot fitted values for different degrees
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Polynomial regression")+
geom_line(data = dat, aes(x = Terminal, y = Outstate, color = degree))
library(splines)
ds = College[c("Expend", "Outstate")]
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline"))
library(splines)
ds = College[c("Expend", "Outstate")]
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline")
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
library(splines)
ds = College[c("Expend", "Outstate")]
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline")
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_lines(fit, col="red", lwd=2)
#legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
?ggplot
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + lines(fit, col="red", lwd=2)
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_abline(fit, col="red", lwd=2)
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate) ) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_abline(fit, col="red")
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate) ) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_abline(fit, color="red") + geom_abline()
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate) ) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_abline(fit, color="red")
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate) ) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_abline(fit,aes(x = Expend, y = Outstate) color="red")
library(splines)
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(splines)
#plot training set for Expend as only covariate
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
#perform CV in order to find optimal number of df
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#add fitted function from smoothing spline
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
#MSE for polynomial regression models (1-10)
MSE
#MSE for smoothing spline
pred = predict(fit, newdata=college.train)
#MSE2 = mean( (college.train$Outstate - pred)^2 )
#MSE2
#MSE for polynomial regression models (1-10)
plot(MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
MSE
MSE[-1]
MSE[,-1]
MSE[1]
MSE[10]
MSE[11]
#MSE for polynomial regression models (1-10)
plot(MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
#MSE for polynomial regression models (1-10)
#make dataframe for MSE for each degree
MSEdata = data.frame(MSE = MSE, degree = 1:10)
ggplot(data = MSEdata, aes(x = degree, y = MSE)) + geom_line() + geom_point() +
labs(title = "Test error")
library(ggplot2)
#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values for each degree
MSE = list(rep(0, 10))  #make a empty variable to store MSE for each degree
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[train.ind, ])
#dataframe for Terminal and Outstate showing result for each degree over all samples
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit,
degree = as.factor(rep(d,length(mod$fit)))))
# training MSE
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-train.ind, 2])^2)
}
# plot fitted values for different degrees
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Polynomial regression")+
geom_line(data = dat, aes(x = Terminal, y = Outstate, color = degree))
library(splines)
#plot training set for Expend as only covariate
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
#perform CV in order to find optimal number of df
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#add fitted function from smoothing spline
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
#MSE for polynomial regression models (1-10)
#make dataframe for MSE for each degree
MSEdata = data.frame(MSE = MSE, degree = 1:10)
ggplot(data = MSEdata, aes(x = degree, y = MSE)) + geom_line() + geom_point() +
labs(title = "Test error")
#MSE for polynomial regression models (1-10)
MSEdata = data.frame(MSE = MSE, degree = 1:10)
ggplot(data = MSEdata, aes(x = degree, y = MSE)) + geom_line() + geom_point() +
labs(title = "Test error")
MSEdata
#MSE for polynomial regression models (1-10)
MSE
#MSE for smoothing spline
pred = predict(fit, newdata=college.train)
#MSE2 = mean( (college.train$Outstate - pred)^2 )
#MSE2
#MSE for polynomial regression models (1-10)
MSE
#MSE for polynomial regression models (1-10)
plot(MSE)
MSEdata
#MSE for polynomial regression models (1-10)
# plot MSE
MSEdata = data.frame(MSE = MSE, degree = 1:10)
ggplot(data = MSEdata, aes(x = degree, y = MSEdata)) + geom_line() + geom_point() +
labs(title = "Test error")
#MSE for polynomial regression models (1-10)
# plot MSE
MSEdata = data.frame(MSE = MSE, degree = 1:10)
ggplot(data = MSEdata, aes(x = degree, y = MSE)) + geom_line() + geom_point() +
labs(title = "Test error")
ggplot(data = MSEdata, aes(x = degree, y = MSEdata)) + geom_line() + geom_point() +
labs(title = "Test error")
#MSE for polynomial regression models (1-10)
# plot MSE
MSEdata = data.frame(MSE = MSE, degree = 1:10)
length(MSEdata)
ggplot(data = MSEdata, aes(x = degree, y = MSEdata)) + geom_line() + geom_point() +
labs(title = "Test error")
MSEdata
length(MSE)
MSE
ggplot(data = MSEdata, aes(x = degree, y = MSE)) + geom_line() + geom_point() +
labs(title = "Test error")
MSE
#MSE for polynomial regression models (1-10)
# plot MSE
plot(1:10,MSE)
#MSE for smoothing spline
pred = predict(fit, newdata=college.train)
#MSE2 = mean( (college.train$Outstate - pred)^2 )
#MSE2
#MSE for polynomial regression models (1-10)
# plot MSE
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
#MSE for smoothing spline
pred = predict(fit, newdata=college.train)
#MSE2 = mean( (college.train$Outstate - pred)^2 )
#MSE2
pred = predict(fit, newdata=college.train)
pred
pred = predict(fit, newdata=college.train)
MSE2 = mean( (college.train$Outstate - pred$y)^2 )
MSE2
#MSE for polynomial regression models (1-10)
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
#MSE for smoothing spline
MSE2
MSE[9]
max(MSE)
max(MSE)
#MSE for polynomial regression models (1-10)
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
#MSE for smoothing spline
MSE2
#MSE for polynomial regression models (1-10)
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
MSE
#MSE for smoothing spline
MSE2
#MSE for polynomial regression models (1-10)
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
MSE[9]
#MSE for smoothing spline
MSE2
fit$lambda
fit$lambda
#MSE for polynomial regression models (1-10)
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
MSE[9]
#MSE for smoothing spline
MSE2
MSE[3]
#MSE for smoothing spline
MSE2
MSE[3]
#MSE for smoothing spline
MSE2
pr.tree = prune.tree(tree.mod, best = 7)
library(tree)
tree.mod = tree(Outstate ~ .,college.train)
summary(tree.mod)
plot(tree.mod)
text(tree.mod, pretty = 0)
train.ind
library(tree)
#make new training and testing set
new.train.ind = sample(1:nrow(college.train), 0.5 * nrow(college.train))
new.college.train1 = College[new.train.ind, ]
new.college.train2 = College[-new.train.ind, ]
tree.mod = tree(Outstate ~ .,new.college.train)
library(tree)
#make new training and testing set
new.train.ind = sample(1:nrow(college.train), 0.5 * nrow(college.train))
new.college.train1 = college.train[new.train.ind, ]
new.college.train2 = college.train[-new.train.ind, ]
tree.mod = tree(Outstate ~ .,new.college.train)
library(tree)
#make new training and testing set
new.train.ind = sample(1:nrow(college.train), 0.5 * nrow(college.train))
new.college.train1 = college.train[new.train.ind, ]
new.college.train2 = college.train[-new.train.ind, ]
tree.mod = tree(Outstate ~ .,new.college.train1)
summary(tree.mod)
library(tree)
#make new training and testing set
new.train.ind = sample(1:nrow(college.train), 0.5 * nrow(college.train))
new.college.train1 = college.train[new.train.ind, ]
new.college.train2 = college.train[-new.train.ind, ]
tree.mod1 = tree(Outstate ~ .,new.college.train1)
tree.mod2 = tree(Outstate ~ .,new.college.train2)
summary(tree.mod)
plot(tree.mod1)
text(tree.mod1, pretty = 0)
plot(tree.mod2)
text(tree.mod2, pretty = 0)
