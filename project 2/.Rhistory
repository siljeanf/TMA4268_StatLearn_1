cv.linear = tune(svm, formula, data=data.fram(d.train), kernel = "linear", ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- d.train$diabetes ~ npreg + glu + bp + skin + bmi + ped + age
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find good cost parameter and gamma
cv.linear = tune(svm, formula, data=data.frame(d.train), kernel = "linear", ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
d.train
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- d.train$diabetes ~ npreg + glu + bp + skin + bmi + ped + age
d.train
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find good cost parameter and gamma
cv.linear = tune(svm, formula, data=d.train, kernel = "linear", ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- d.train$diabetes ~ npreg + glu + bp + skin + bmi + ped + age
d.train
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find good cost parameter and gamma
cv.linear = tune(svm, formula, data=d.train, kernel = "linear",tunecontrol = tune.control(sampling = "fix"), ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.linear = tune(svm, formula, data=d.train, kernel = "linear",tunecontrol = tune.control(sampling = "fix"), ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.linear = tune(svm, formula, data=d.train, kernel = "linear",tunecontrol = tune.control(sampling = "fix"), ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.linear = tune(svm, formula, data=d.train, kernel = "linear",tunecontrol = tune.control(sampling = "fix"), ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.linear = tune(svm, formula, data=d.train, kernel = "linear",tunecontrol = tune.control(sampling = "fix"), ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.linear = tune(svm, formula, data=d.train, kernel = "linear",tunecontrol = tune.control(sampling = "fix"), ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- d.train$diabetes ~ npreg + glu + bp + skin + bmi + ped + age
d.train
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find good cost parameter and gamma
cv.linear = tune(svm, d.diabetes~., data=d.train, kernel = "linear",tunecontrol = tune.control(sampling = "fix"), ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- d.train$diabetes ~ npreg + glu + bp + skin + bmi + ped + age
d.train
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find good cost parameter and gamma
cv.linear = tune(svm, diabetes~., data=d.train, kernel = "linear",tunecontrol = tune.control(sampling = "fix"), ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
summary(cv.linear)
bestmod.linear = cv.linear$best.model
cv.radial <- tune(svm.radial, d.train$diabetes ~., data = d.train, kernel = "radial", tunecontrol = tune.control(sampling = "fix")
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- d.train$diabetes ~ npreg + glu + bp + skin + bmi + ped + age
d.train
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find good cost parameter and gamma
cv.linear = tune(svm, diabetes~., data=d.train, kernel = "linear", ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
summary(cv.linear)
bestmod.linear = cv.linear$best.model
cv.radial <- tune(svm.radial, d.train$diabetes ~., data = d.train, kernel = "radial", tunecontrol = tune.control(sampling = "fix")
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- diabetes ~ .
d.train
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find good cost parameter and gamma
cv.linear = tune(svm, diabetes~., data=d.train, kernel = "linear", ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
summary(cv.linear)
bestmod.linear = cv.linear$best.model
cv.radial <- tune(svm, diabetes ~., data = d.train, kernel = "radial", tunecontrol = tune.control(sampling = "fix")
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- diabetes ~ .
d.train
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find good cost parameter and gamma
cv.linear = tune(svm, formula, data=d.train, kernel = "linear", ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
summary(cv.linear)
bestmod.linear = cv.linear$best.model
cv.radial <- tune(svm, formula, data = d.train, kernel = "radial",
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
summary(cv.radial)
bestmod.radial = cv.radial$best.model
# Predicting the response with test set
y.pred = predict(svm.linear, newdata = d.test)
# Making the Confusion Matrix
cm = table(predict = y.pred, truth = d.test$diabetes)
#misclassification error rates
?tune
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- diabetes ~ .
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find good cost parameter and gamma
cv.linear <- tune(svm, formula, data=d.train, kernel = "linear", ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
summary(cv.linear)
bestmod.linear = cv.linear$best.model
cv.radial <- tune(svm, formula, data = d.train, kernel = "radial",
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
summary(cv.radial)
bestmod.radial = cv.radial$best.model
# Predicting the response with test set
y.pred = predict(svm.linear, newdata = d.test)
# Making the Confusion Matrix
cm = table(predict = y.pred, truth = d.test$diabetes)
#misclassification error rates
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- diabetes ~ .
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find good cost parameter and gamma
cv.linear <- tune(svm, formula, data=d.train, kernel = "linear",
ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.radial <- tune(svm, formula, data = d.train, kernel = "radial",
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
#fit new method with the optimalized parameters from CV
bestmod.linear = cv.linear$best.model
bestmod.radial = cv.radial$best.model
# Predicting the response with test set
y.pred.lin = predict(bestmod.linear, newdata = d.test)
y.pred.rad = predict(bestmod.radial, newdata = d.test)
# Making the Confusion Matrix
cm.lin = table(predict = y.pred.lin, truth = d.test$diabetes)
cm.rad = table(predict= y.pred.rad, truth = d.test$diabetes)
#misclassification error rates
cm.lin
cm.rad
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- diabetes ~ .
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find the best parameters for each model
cv.linear <- tune(svm, formula, data=d.train, kernel = "linear",
ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.radial <- tune(svm, formula, data = d.train, kernel = "radial",
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
#fit new models with the optimalized parameters from CV
bestmod.linear = cv.linear$best.model
bestmod.radial = cv.radial$best.model
# Predict the response for the test set
y.pred.lin = predict(bestmod.linear, newdata = d.test)
y.pred.rad = predict(bestmod.radial, newdata = d.test)
# Confusion tables
cm.lin = table(predict = y.pred.lin, truth = d.test$diabetes)
cm.rad = table(predict= y.pred.rad, truth = d.test$diabetes)
cm.lin
cm.rad
#misclassification error rates (off-diagonal elements)
table(predict = y.pred.lin, truth = d.test$diabetes)
library(e1071)
set.seed(10111)
#define formula for our response and predictors
formula <- diabetes ~ .
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find the best parameters for each model
cv.linear <- tune(svm, formula, data=d.train, kernel = "linear",
ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.radial <- tune(svm, formula, data = d.train, kernel = "radial",
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
#fit new models with the optimalized parameters from CV
bestmod.linear = cv.linear$best.model
bestmod.radial = cv.radial$best.model
# Predict the response for the test set
y.pred.lin = predict(svm.linear, newdata = d.test)
y.pred.rad = predict(bestmod.radial, newdata = d.test)
# Confusion tables
table(predict = y.pred.lin, truth = d.test$diabetes)
table(predict = y.pred.rad, truth = d.test$diabetes)
#misclassification error rates (off-diagonal elements)
y.pred.lin
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
colnames(t)=c("Predicted Loss","Predicted Win")
rownames(t)=c("Actual Loss","Actual Win")
# Confusion tables
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
t
confusionMatrix(predict = y.pred.lin, truth = d.test$diabetes)
# Confusion tables
table(predict = y.pred.lin, truth = d.test$diabetes)
?table
table(predict = y.pred.lin, truth = d.test$diabetes)
table(predict = y.pred.rad, truth = d.test$diabetes)
library(e1071)
set.seed(10111)
d.train$diabetes <- as.factor(d.train$diabetes)
d.test$diabetes <- as.factor(d.test$diabetes)
#define formula for our response and predictors
formula <- d.train$diabetes ~ .
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find the best parameters for each model
cv.linear <- tune(svm, formula, data=d.train, kernel = "linear",
ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
library(e1071)
set.seed(10111)
d.train$diabetes <- as.factor(d.train$diabetes)
d.test$diabetes <- as.factor(d.test$diabetes)
#define formula for our response and predictors
formula <- d.train$diabetes ~ .
#Fit a support vector classifier (linear boundary)
svm.linear = svm(formula,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(formula,
data = d.train,
kernel = 'radial')
#CV to find the best parameters for each model
cv.linear <- tune(svm, diabetes ~ ., data=d.train, kernel = "linear",
ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.radial <- tune(svm, formula, data = d.train, kernel = "radial",
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
library(e1071)
set.seed(10111)
diabetes <- as.factor(d.train$diabetes)
diabetes <- as.factor(d.test$diabetes)
#Fit a support vector classifier (linear boundary)
svm.linear = svm(diabetes~.,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(diabetes~.,
data = d.train,
kernel = 'radial')
#CV to find the best parameters for each model
cv.linear <- tune(svm, diabetes ~ ., data=d.train, kernel = "linear",
ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.radial <- tune(svm, diabetes ~., data = d.train, kernel = "radial",
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
#fit new models with the optimalized parameters from CV
bestmod.linear = cv.linear$best.model
bestmod.radial = cv.radial$best.model
# Predict the response for the test set
y.pred.lin = predict(bestmod.linear, newdata = d.test)
y.pred.rad = predict(bestmod.radial, newdata = d.test)
# Confusion tables
table(predict = y.pred.lin, truth = d.test$diabetes)
table(predict = y.pred.rad, truth = d.test$diabetes)
#misclassification error rates (off-diagonal elements)
# Confusion tables
table(predict = y.pred.lin, truth = d.test$diabetes, main=".")
# Confusion tables
?table
table(predict = y.pred.lin, truth = d.test$diabetes)
table(predict = y.pred.rad, truth = d.test$diabetes)
table(predict = y.pred.lin, truth = d.test$diabetes, row.names=c(",", "cc"))
table(predict = y.pred.lin, truth = d.test$diabetes, row.names=c(",") )
table(predict = y.pred.lin, truth = d.test$diabetes, row.names=",." )
table(predict = y.pred.lin, truth = d.test$diabetes, row.names=",." )
library(e1071)
set.seed(10111)
diabetes <- as.factor(d.train$diabetes)
diabetes <- as.factor(d.test$diabetes)
#Fit a support vector classifier (linear boundary)
svm.linear = svm(diabetes~.,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(diabetes~.,
data = d.train,
kernel = 'radial')
#CV to find the best parameters for each model
cv.linear <- tune(svm, diabetes ~ ., data=d.train, kernel = "linear",
ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.radial <- tune(svm, diabetes ~., data = d.train, kernel = "radial",
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
#fit new models with the optimalized parameters from CV
bestmod.linear = cv.linear$best.model
bestmod.radial = cv.radial$best.model
# Predict the response for the test set
y.pred.lin = predict(bestmod.linear, newdata = d.test)
y.pred.rad = predict(bestmod.radial, newdata = d.test)
# Confusion tables
#for SVC (linear)
t <- table(predict = y.pred.lin, truth = d.test$diabetes, row.names=",." )
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
rname <- rbind(as.numeric(names(a)), a)
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
rname <- rbind(as.numeric(names(t)), t)
rownames(rname) <- c("Faces", "Count")
t
rname
rownames(t1) <- c("Faces", "Count")
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
t1 <- rbind(as.numeric(names(t)), t)
rownames(t1) <- c("Faces", "Count")
t1
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
t1 <- rbind(as.numeric(names(t)), t)
rownames(t1) <- c("No diabetes", "diabetes")
t1
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
t1 <- rbind(as.numeric(names(t)), t)
rownames(t1) <- c("No diabetes", "diabetes")
colnames(t1) <- c("No diabetes", "diabetes")
t1
library(e1071)
set.seed(10111)
diabetes <- as.factor(d.train$diabetes)
diabetes <- as.factor(d.test$diabetes)
#Fit a support vector classifier (linear boundary)
svm.linear = svm(diabetes~.,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(diabetes~.,
data = d.train,
kernel = 'radial')
#CV to find the best parameters for each model
cv.linear <- tune(svm, diabetes ~ ., data=d.train, kernel = "linear",
ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.radial <- tune(svm, diabetes ~., data = d.train, kernel = "radial",
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
#fit new models with the optimalized parameters from CV
bestmod.linear = cv.linear$best.model
bestmod.radial = cv.radial$best.model
# Predict the response for the test set
y.pred.lin = predict(bestmod.linear, newdata = d.test)
y.pred.rad = predict(bestmod.radial, newdata = d.test)
# Confusion tables
#for SVC (linear)
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
t1 <- rbind(as.numeric(names(t)), t)
rownames(t1) <- c("No diabetes (prediction)", "diabetes (predicion)")
colnames(t1) <- c("No diabetes (truth) ", "diabetes (truth)")
t1
#for SVM (radial)
table(predict = y.pred.rad, truth = d.test$diabetes)
#misclassification error rates (off-diagonal elements)
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
t1 <- rbind(as.numeric(names(t)), t)
rownames(t1) <- c("No diabetes (prediction)", "diabetes (predicion)")
colnames(t1) <- c("No diabetes (truth) ", "diabetes (truth)")
t1
names(dimnames(t1)) <- list("", "Nutritional Status")
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
t1 <- rbind(as.numeric(names(t)), t)
rownames(t1) <- c("No diabetes (prediction)", "diabetes (predicion)")
colnames(t1) <- c("No diabetes (truth) ", "diabetes (truth)")
names(dimnames(t1)) <- list("", "Nutritional Status")
t1
names(dimnames(t1)) <- list("Prediction", "Truth")
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
t1 <- rbind(as.numeric(names(t)), t)
rownames(t1) <- c("No diabetes (prediction)", "diabetes (predicion)")
colnames(t1) <- c("No diabetes (truth) ", "diabetes (truth)")
names(dimnames(t1)) <- list("Prediction", "Truth")
t1
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
t1 <- rbind(as.numeric(names(t)), t)
rownames(t1) <- c("No diabetes", "diabetes")
colnames(t1) <- c("No diabetes ", "diabetes")
names(dimnames(t1)) <- list("Prediction", "Truth")
t1
t1 <- rbind(as.numeric(names(t)), t)
t <- table(predict = y.pred.lin, truth = d.test$diabetes)
t1 <- rbind(as.numeric(names(t)), t)
names(dimnames(t1)) <- list("Prediction", "Truth")
t1
t
t1
t
t1
t
t <- table(Prediction = y.pred.lin, Truth = d.test$diabetes)
t1 <- rbind(as.numeric(names(t)), t)
names(dimnames(t1)) <- list("Prediction", "Truth")
t1
t
t <- table(Prediction = y.pred.lin, Truth = d.test$diabetes)
names(dimnames(t)) <- list("Prediction", "Truth")
t
names(dimnames(t)) <- list("hei", "Truth")
t <- table(Prediction = y.pred.lin, Truth = d.test$diabetes)
names(dimnames(t)) <- list("hei", "Truth")
t
t
t <- table(Prediction = y.pred.lin, Truth = d.test$diabetes)
t
# Confusion tables (0: no diabetes, 1: diabetes)
#for SVC (linear)
table(Prediction = y.pred.lin, Truth = d.test$diabetes)
#for SVM (radial)
table(Prediction = y.pred.rad, Truth = d.test$diabetes)
(35+18)/(137+35+18+42)
(38+22)/(133+38+22+39)
library(e1071)
set.seed(10111)
diabetes <- as.factor(d.train$diabetes)
diabetes <- as.factor(d.test$diabetes)
#Fit a support vector classifier (linear boundary)
svm.linear = svm(diabetes~.,
data = d.train,
kernel = 'linear')
#fit a support vector machine (radial boundary)
svm.radial = svm(diabetes~.,
data = d.train,
kernel = 'radial')
#CV to find the best parameters for each model
cv.linear <- tune(svm, diabetes ~ ., data=d.train, kernel = "linear",
ranges = list(cost = c(.001, .01 , .1, 1, 10, 100 ) ) )
cv.radial <- tune(svm, diabetes ~., data = d.train, kernel = "radial",
ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4) ))
#fit new models with the optimalized parameters from CV
bestmod.linear = cv.linear$best.model
bestmod.radial = cv.radial$best.model
# Predict the response for the test set
y.pred.lin = predict(bestmod.linear, newdata = d.test)
y.pred.rad = predict(bestmod.radial, newdata = d.test)
# Confusion tables (0: no diabetes, 1: diabetes)
#for SVC (linear)
table(Prediction = y.pred.lin, Truth = d.test$diabetes)
#for SVM (radial)
table(Prediction = y.pred.rad, Truth = d.test$diabetes)
