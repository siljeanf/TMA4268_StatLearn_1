#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
# plot of training data
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) + geom_point(color = "darkgrey") +
labs(title = "Polynomial regression")
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values
MSE = list(rep(0, 10))  #make a empty variable to store predicted values
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[train.ind, ])
# dataframe of predicted values - use fitted values (for mpg) and horsepower
# from training set and add column (factor) for degree
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit, degree = as.factor(rep(d,
length(mod$fit)))))
# calculate mean MSE - this is returned in the MSE variable
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-train.ind, 2])^2)
}
# plot fitted values for different degrees
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) + geom_point(color = "darkgrey") +
labs(title = "Polynomial regression") + geom_line(data = dat, aes(x = Terminal,
y = Outstate, color = degree))
library(ggplot2)
#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values
MSE = list(rep(0, 10))  #make a empty variable to store predicted values
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[train.ind, ])
# dataframe of predicted values - use fitted values (for mpg) and horsepower
# from training set and add column (factor) for degree
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit, degree = as.factor(rep(d,
length(mod$fit)))))
# calculate mean MSE - this is returned in the MSE variable
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-train.ind, 2])^2)
}
# plot fitted values for different degrees
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) + geom_point(color = "darkgrey") +
labs(title = "Polynomial regression") + geom_line(data = dat, aes(x = Terminal,
y = Outstate, color = degree))
?rbind
rbind
dat
library(splines)
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(splines)
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Outstate", ylab="Expend",)
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(splines)
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate",)
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(splines)
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(ggplot2)
#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values for each degree
MSE = list(rep(0, 10))  #make a empty variable to store MSE for each degree
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[train.ind, ])
#dataframe for Terminal and Outstate showing result for each degree over all samples
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit,
degree = as.factor(rep(d,length(mod$fit)))))
# training MSE
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-train.ind, 2])^2)
}
# plot fitted values for different degrees
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Polynomial regression")+
geom_line(data = dat, aes(x = Terminal, y = Outstate, color = degree))
library(splines)
ds = College[c("Expend", "Outstate")]
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline"))
library(splines)
ds = College[c("Expend", "Outstate")]
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline")
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
library(splines)
ds = College[c("Expend", "Outstate")]
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline")
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_lines(fit, col="red", lwd=2)
#legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
?ggplot
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + lines(fit, col="red", lwd=2)
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_abline(fit, col="red", lwd=2)
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate) ) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_abline(fit, col="red")
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate) ) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_abline(fit, color="red") + geom_abline()
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate) ) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_abline(fit, color="red")
library(splines)
ds = College[c("Expend", "Outstate")]
#plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#lines(fit, col="red", lwd=2)
ggplot(data = ds[train.ind, ], aes(x = Expend, y = Outstate) ) +
geom_point(color = "darkgrey") + labs(title = "Smoothing spline") + geom_abline(fit,aes(x = Expend, y = Outstate) color="red")
library(splines)
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
library(splines)
#plot training set for Expend as only covariate
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
#perform CV in order to find optimal number of df
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#add fitted function from smoothing spline
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
#MSE for polynomial regression models (1-10)
MSE
#MSE for smoothing spline
pred = predict(fit, newdata=college.train)
#MSE2 = mean( (college.train$Outstate - pred)^2 )
#MSE2
#MSE for polynomial regression models (1-10)
plot(MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
MSE
MSE[-1]
MSE[,-1]
MSE[1]
MSE[10]
MSE[11]
#MSE for polynomial regression models (1-10)
plot(MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
#MSE for polynomial regression models (1-10)
#make dataframe for MSE for each degree
MSEdata = data.frame(MSE = MSE, degree = 1:10)
ggplot(data = MSEdata, aes(x = degree, y = MSE)) + geom_line() + geom_point() +
labs(title = "Test error")
library(ggplot2)
#make a dataframe
ds = College[c("Terminal", "Outstate")]
n = nrow(ds)
# chosen degrees
deg = 1:10
#now iterate over each degree d
dat = c()  #make a empty variable to store predicted values for each degree
MSE = list(rep(0, 10))  #make a empty variable to store MSE for each degree
for (d in deg) {
# fit model with this degree
mod = lm(Outstate ~ poly(Terminal, d), ds[train.ind, ])
#dataframe for Terminal and Outstate showing result for each degree over all samples
dat = rbind(dat, data.frame(Terminal = ds[train.ind, 1], Outstate = mod$fit,
degree = as.factor(rep(d,length(mod$fit)))))
# training MSE
MSE[d] = mean((predict(mod, ds[-train.ind, ]) - ds[-train.ind, 2])^2)
}
# plot fitted values for different degrees
ggplot(data = ds[train.ind, ], aes(x = Terminal, y = Outstate)) +
geom_point(color = "darkgrey") + labs(title = "Polynomial regression")+
geom_line(data = dat, aes(x = Terminal, y = Outstate, color = degree))
library(splines)
#plot training set for Expend as only covariate
plot(college.train$Expend, college.train$Outstate, col = "darkgrey", main="Smoothing spline", xlab="Expend", ylab="Outstate")
#perform CV in order to find optimal number of df
fit = smooth.spline(college.train$Expend, college.train$Outstate, cv=TRUE)
fit$df #choose df from CV
#add fitted function from smoothing spline
lines(fit, col="red", lwd=2)
legend("topright", legend=c("4.6 DF"), col="red", lty=1, lwd=2, cex=.8)
#MSE for polynomial regression models (1-10)
#make dataframe for MSE for each degree
MSEdata = data.frame(MSE = MSE, degree = 1:10)
ggplot(data = MSEdata, aes(x = degree, y = MSE)) + geom_line() + geom_point() +
labs(title = "Test error")
#MSE for polynomial regression models (1-10)
MSEdata = data.frame(MSE = MSE, degree = 1:10)
ggplot(data = MSEdata, aes(x = degree, y = MSE)) + geom_line() + geom_point() +
labs(title = "Test error")
MSEdata
#MSE for polynomial regression models (1-10)
MSE
#MSE for smoothing spline
pred = predict(fit, newdata=college.train)
#MSE2 = mean( (college.train$Outstate - pred)^2 )
#MSE2
#MSE for polynomial regression models (1-10)
MSE
#MSE for polynomial regression models (1-10)
plot(MSE)
MSEdata
#MSE for polynomial regression models (1-10)
# plot MSE
MSEdata = data.frame(MSE = MSE, degree = 1:10)
ggplot(data = MSEdata, aes(x = degree, y = MSEdata)) + geom_line() + geom_point() +
labs(title = "Test error")
#MSE for polynomial regression models (1-10)
# plot MSE
MSEdata = data.frame(MSE = MSE, degree = 1:10)
ggplot(data = MSEdata, aes(x = degree, y = MSE)) + geom_line() + geom_point() +
labs(title = "Test error")
ggplot(data = MSEdata, aes(x = degree, y = MSEdata)) + geom_line() + geom_point() +
labs(title = "Test error")
#MSE for polynomial regression models (1-10)
# plot MSE
MSEdata = data.frame(MSE = MSE, degree = 1:10)
length(MSEdata)
ggplot(data = MSEdata, aes(x = degree, y = MSEdata)) + geom_line() + geom_point() +
labs(title = "Test error")
MSEdata
length(MSE)
MSE
ggplot(data = MSEdata, aes(x = degree, y = MSE)) + geom_line() + geom_point() +
labs(title = "Test error")
MSE
#MSE for polynomial regression models (1-10)
# plot MSE
plot(1:10,MSE)
#MSE for smoothing spline
pred = predict(fit, newdata=college.train)
#MSE2 = mean( (college.train$Outstate - pred)^2 )
#MSE2
#MSE for polynomial regression models (1-10)
# plot MSE
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
#MSE for smoothing spline
pred = predict(fit, newdata=college.train)
#MSE2 = mean( (college.train$Outstate - pred)^2 )
#MSE2
pred = predict(fit, newdata=college.train)
pred
pred = predict(fit, newdata=college.train)
MSE2 = mean( (college.train$Outstate - pred$y)^2 )
MSE2
#MSE for polynomial regression models (1-10)
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
#MSE for smoothing spline
MSE2
MSE[9]
max(MSE)
max(MSE)
#MSE for polynomial regression models (1-10)
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
#MSE for smoothing spline
MSE2
#MSE for polynomial regression models (1-10)
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
MSE
#MSE for smoothing spline
MSE2
#MSE for polynomial regression models (1-10)
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
MSE[9]
#MSE for smoothing spline
MSE2
fit$lambda
fit$lambda
#MSE for polynomial regression models (1-10)
plot(1:10,MSE, type = "o", pch = 16, xlab = "degree", main = "Test error")
MSE[9]
#MSE for smoothing spline
MSE2
MSE[3]
#MSE for smoothing spline
MSE2
MSE[3]
#MSE for smoothing spline
MSE2
pr.tree = prune.tree(tree.mod, best = 7)
library(tree)
tree.mod = tree(Outstate ~ .,college.train)
summary(tree.mod)
plot(tree.mod)
text(tree.mod, pretty = 0)
train.ind
library(tree)
#make new training and testing set
new.train.ind = sample(1:nrow(college.train), 0.5 * nrow(college.train))
new.college.train1 = College[new.train.ind, ]
new.college.train2 = College[-new.train.ind, ]
tree.mod = tree(Outstate ~ .,new.college.train)
library(tree)
#make new training and testing set
new.train.ind = sample(1:nrow(college.train), 0.5 * nrow(college.train))
new.college.train1 = college.train[new.train.ind, ]
new.college.train2 = college.train[-new.train.ind, ]
tree.mod = tree(Outstate ~ .,new.college.train)
library(tree)
#make new training and testing set
new.train.ind = sample(1:nrow(college.train), 0.5 * nrow(college.train))
new.college.train1 = college.train[new.train.ind, ]
new.college.train2 = college.train[-new.train.ind, ]
tree.mod = tree(Outstate ~ .,new.college.train1)
summary(tree.mod)
library(tree)
#make new training and testing set
new.train.ind = sample(1:nrow(college.train), 0.5 * nrow(college.train))
new.college.train1 = college.train[new.train.ind, ]
new.college.train2 = college.train[-new.train.ind, ]
tree.mod1 = tree(Outstate ~ .,new.college.train1)
tree.mod2 = tree(Outstate ~ .,new.college.train2)
summary(tree.mod)
plot(tree.mod1)
text(tree.mod1, pretty = 0)
plot(tree.mod2)
text(tree.mod2, pretty = 0)
install.packages("formattable")
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=68),tidy=TRUE)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
cache=TRUE, size="scriptsize")
id <- "1VfVCQvWt121UN39NXZ4aR9Dmsbj-p9OU"  # google file ID
GeneData <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download",
id), header = F)
colnames(GeneData)[1:20] = paste(rep("H", 20), c(1:20), sep = "")
colnames(GeneData)[21:40] = paste(rep("D", 20), c(1:20), sep = "")
row.names(GeneData) = paste(rep("G", 1000), c(1:1000), sep = "")
head(GeneData)
hc.complete=hclust(dist(GeneData), method="complete")
hc.average=hclust(dist(GeneData), method="average")
hc.single=hclust(dist(GeneData), method="single")
par(mfrow=c(1,3))
plot(hc.complete,main="Complete Linkage", xlab="", sub="", cex=.9)
plot(hc.average, main="Average Linkage", xlab="", sub="", cex=.9)
plot(hc.single, main="Single Linkage", xlab="", sub="", cex=.9)
id <- "1VfVCQvWt121UN39NXZ4aR9Dmsbj-p9OU"  # google file ID
GeneData <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download",
id), header = F)
colnames(GeneData)[1:20] = paste(rep("H", 20), c(1:20), sep = "")
colnames(GeneData)[21:40] = paste(rep("D", 20), c(1:20), sep = "")
row.names(GeneData) = paste(rep("G", 1000), c(1:1000), sep = "")
GeneData=t(GeneData)
hc.complete=hclust(dist(GeneData), method="complete")
hc.average=hclust(dist(GeneData), method="average")
hc.single=hclust(dist(GeneData), method="single")
par(mfrow=c(1,3))
plot(hc.complete,main="Complete Linkage", xlab="", sub="", cex=.9)
plot(hc.average, main="Average Linkage", xlab="", sub="", cex=.9)
plot(hc.single, main="Single Linkage", xlab="", sub="", cex=.9)
hc.complete=hclust(dist(GeneData,method="euclidian"), method="complete")
hc.average=hclust(dist(GeneData), method="average")
hc.single=hclust(dist(GeneData), method="single")
par(mfrow=c(1,3))
plot(hc.complete,main="Complete Linkage", xlab="", sub="", cex=.9)
plot(hc.average, main="Average Linkage", xlab="", sub="", cex=.9)
plot(hc.single, main="Single Linkage", xlab="", sub="", cex=.9)
par(mfrow=c(2,3))
plot(hc.eucl.complete,main="Complete Linkage, Euclidian distance", xlab="", sub="", cex=.9)
hc.eucl.complete=hclust(dist(GeneData,method="euclidian"), method="complete")
hc.eucl.average=hclust(dist(GeneData,method="euclidian"), method="average")
hc.eucl.single=hclust(dist(GeneData,method="euclidian"), method="single")
correlation<-as.dist(1-cor(t(GeneData)))
hc.corr.complete=hclust(dd, method="complete")
correlation<-as.dist(1-cor(t(GeneData)))
hc.corr.complete=hclust(correlation, method="complete")
hc.corr.average=hclust(correlation, method="average")
hc.corr.single=hclust(correlation, method="single")
par(mfrow=c(2,3))
plot(hc.eucl.complete,main="Complete Linkage, Euclidian distance", xlab="", sub="", cex=.9)
plot(hc.eucl.average, main="Average Linkage, Euclidian distance", xlab="", sub="", cex=.9)
plot(hc.eucl.single, main="Single Linkage, Euclidian distance", xlab="", sub="", cex=.9)
plot(hc.corr.complete,main="Complete Linkage, correlation-based distance", xlab="", sub="", cex=.9)
plot(hc.corr.average, main="Average Linkage, correlation-based distance", xlab="", sub="", cex=.9)
plot(hc.corr.single, main="Single Linkage, correlation-based distance", xlab="", sub="", cex=.9)
correlation<-as.dist(1-cor(GeneData))
hc.corr.complete=hclust(correlation, method="complete")
hc.corr.average=hclust(correlation, method="average")
hc.corr.single=hclust(correlation, method="single")
par(mfrow=c(2,3))
plot(hc.eucl.complete,main="Complete Linkage, Euclidian distance", xlab="", sub="", cex=.9)
plot(hc.eucl.average, main="Average Linkage, Euclidian distance", xlab="", sub="", cex=.9)
plot(hc.eucl.single, main="Single Linkage, Euclidian distance", xlab="", sub="", cex=.9)
plot(hc.corr.complete,main="Complete Linkage, correlation-based distance", xlab="", sub="", cex=.9)
plot(hc.corr.average, main="Average Linkage, correlation-based distance", xlab="", sub="", cex=.9)
plot(hc.corr.single, main="Single Linkage, correlation-based distance", xlab="", sub="", cex=.9)
correlation<-as.dist(1-cor(t(GeneData)))
hc.corr.complete=hclust(correlation, method="complete")
hc.corr.average=hclust(correlation, method="average")
hc.corr.single=hclust(correlation, method="single")
par(mfrow=c(2,3))
plot(hc.eucl.complete,main="Complete Linkage, Euclidian distance", xlab="", sub="", cex=.9)
plot(hc.eucl.average, main="Average Linkage, Euclidian distance", xlab="", sub="", cex=.9)
plot(hc.eucl.single, main="Single Linkage, Euclidian distance", xlab="", sub="", cex=.9)
plot(hc.corr.complete,main="Complete Linkage, correlation-based distance", xlab="", sub="", cex=.9)
plot(hc.corr.average, main="Average Linkage, correlation-based distance", xlab="", sub="", cex=.9)
plot(hc.corr.single, main="Single Linkage, correlation-based distance", xlab="", sub="", cex=.9)
cutree(hc.eucl.complete, 2)
cutree(hc.eucl.complete, 2)
cutree(hc.eucl.average, 2)
cutree(hc.eucl.single, 2)
cutree(hc.corr.complete, 2)
cutree(hc.corr.average, 2)
cutree(hc.corr.single, 2)
pr.out=prcomp(GeneData, scale=TRUE)
plot(pr.out$x[,1:2], col=Cols(GeneData.labs), pch=19,xlab="Z1",ylab="Z2")
pr.out=prcomp(GeneData, scale=TRUE)
plot(pr.out$x[,1:2], col=GeneData.labs, pch=19,xlab="Z1",ylab="Z2")
pr.out=prcomp(GeneData, scale=TRUE)
plot(pr.out$x[,1:2], pch=19,xlab="Z1",ylab="Z2")
GeneData[1,]
GeneData[1,]
pr.out=prcomp(GeneData, scale=TRUE)
plot(pr.out$x[,1:2], col=GeneData[1:20,],pch=19,xlab="Z1",ylab="Z2")
c(0*10,1*10)
c(rep(1,20),rep(0,20))
color<-c(rep(1,20),rep(0,20))
pr.out=prcomp(GeneData, scale=TRUE)
plot(pr.out$x[,1:2], col=c("red","blue")*color,pch=19,xlab="Z1",ylab="Z2")
pr.out=prcomp(GeneData, scale=TRUE)
plot(pr.out$x[,1:2], col=c("red","blue")color,pch=19,xlab="Z1",ylab="Z2")
pr.out=prcomp(GeneData, scale=TRUE)
plot(pr.out$x[,1:2], col=c("red","blue")[color],pch=19,xlab="Z1",ylab="Z2")
color<-c(rep(1,20),rep(0,20))
pr.out=prcomp(GeneData, scale=TRUE)
plot(pr.out$x[,1:2], col=c("red","blue")[color],pch=19,xlab="Z1",ylab="Z2")
color<-c(rep(1,20),rep(2,20))
pr.out=prcomp(GeneData, scale=TRUE)
plot(pr.out$x[,1:2], col=c("red","blue")[color],pch=19,xlab="Z1",ylab="Z2")
color<-c(rep(1,20),rep(2,20))
pr.out=prcomp(GeneData, scale=TRUE)
plot(pr.out$x[,1:2], col=c("red","blue")[color],pch=19,xlab="Z1",ylab="Z2")
pve=100*pr.out$sdev^2/sum(pr.out$sdev^2)
par(mfrow=c(1,2))
plot(pve,  type="o", ylab="PVE", xlab="Principal Component", col="blue")
plot(cumsum(pve), type="o", ylab="Cumulative PVE", xlab="Principal Component", col="brown3")
pve
pve[5]
cumsum(pve)
cumsum(pve)[5]
pve=100*pr.out$sdev^2/sum(pr.out$sdev^2)
cumsum(pve)[5]
pr.out
summary(pr.out)
