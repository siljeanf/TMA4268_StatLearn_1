
---
subtitle: "TMA4268 Statistical Learning V2019"
title: "Compulsory exercise 2: Group 24"
author: "Silje Anfindsen and Clara Panchaud"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
 # html_document
 pdf_document
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=68),tidy=TRUE)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize")
```

#### Help for equation set-up:
$$
\begin{aligned}
E[(y_0-\hat{f}(x_0))^2]&=  &&\text{definition of y0}\\ 
E[(f(x_0)+\epsilon +\hat{f}(x_0))^2]&=  &&\text{by linearity of the expectation}\\
E[f(x_0)^2]+E[\epsilon^2]+E[\hat{f}(x_0)^2]-2E[f(x_0)\hat{f}(x_0)]+0&=  &&\text{using the definition of variance}\\
f(x_0)^2+Var(\epsilon)+Var(\hat{f}(x_0)) +E[\hat{f}(x_0)]^2-2f(x_0)E[\hat{f}(x_0)]&= \\ \underbrace{\text{Var}(\varepsilon)}_{\text{Irreducible error}}+ \underbrace{\text{Var}(\hat{f}(x_0))}_{\text{Variance of prediction}} + \underbrace{\left( f(x_0) - \text{E}[\hat{f}(x_0)] \right)^2}_{\text{Squared bias}}
\end{aligned}
$$

# Problem 1

## a)


## b)


## c)

## d)

```{r, echo=TRUE, eval=TRUE}
library(ISLR)
set.seed(1)
train.ind = sample(1:nrow(College), 0.5 * nrow(College))
college.train = College[train.ind, ]
college.test = College[-train.ind, ]
str(College)

```

## e)

```{r, echo=TRUE, eval=TRUE}


```


# Problem 2

## a)

## b) 

## c)

## d)


# Problem 3

## a)

## b)

## c)


# Problem 4

## a)


## b)

## c)


## d)

# Problem 5

## a)

## b)

## c)

## d)

## e)

## f)


# References

James, G., D. Witten, T. Hastie, and R. Tibshirani. 2013. An Introduction to Statistical Learning with Applications in R. New York: Springer.




